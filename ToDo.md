# To Do 
- [ ] Create CRON job that runs the script every few months using second cloud func, checking for updates on all the Wikis and exporting and updating the neccessary files (https://www.youtube.com/watch?v=2OwLb-aaiBQ). 
- [ ] Check variable naming conventions (https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html).
- [X] Check output of bandit and flake8 check.
- [X] Export updates to csv, dataframe.
- [X] Create API so each ISO3166-2 update info can be retrieved as json format, using GCP.
- [X] Create demo using python notebook.
- [X] Generate updated for a particular year. 
- [X] Change all instances of iso3166-updates to iso3166_updates except for pypi name.
- [X] Add GCP upload to workflow.
- [X] Upload all iso3166-updates for all countries in seperate folder of main repo dir.
- [X] If single ISO code put in then print, if mutliple then output to files.
- [X] Append date to update filenames.
- [X] Add maintainer and keywords to setup.py & cfg.
- [X] When using Year var, if DF empty then don't export it.
- [X] Change "Effective date of change" column to "Date issued"
- [X] Change "Newsletter" column to "Edition/Newsletter"
- [X] All countries should have 4 columns: "Edition/Newsletter", "Date issued", "Description of change in newsletter", "Code/Subdivision change"
- [X] href of newsletter not exporting to json
- [X] Add build passing to readme
- [X] Add format section to README and demo.
- [X] Remove .DS_Store and pycache from repo.
- [X] Add API/Google Cloud code to its own folder in repo.
- [ ] Make Source repo on GCP, use as import to Cloud Function (https://www.youtube.com/watch?v=LAcErtGU-VU). Creat Cloud Build that builds on push to branch, using repo as source.
- [X] Add diagram of cloud arch & pipeline in API fodler: https://medium.com/google-cloud/use-multiple-paths-in-cloud-functions-python-and-flask-fc6780e560d3
- [X] Add API tests for tests folder - iterate through all iso codes confirming that successful response code returned.
- [ ] Update/upload iso3166-updates.json to GCP Stroage in github workflow (https://sha.ws/automatic-upload-to-google-cloud-storage-with-github-actions.html).
- [X] Update Google Cloud Function on push to repo in workflow - if changes made to its folder.
- [X] Add in readme/demo how to use API with requests library.
- [X] Return multiple updates if array of iso_codes applied.
- [X] Replace any null columns with empty string.
- [ ] Go through each country and respective ISO3166-2 wiki URL to verify if it's all correct in json.
- [X] Change iso_code to alpha2_code
- [X] Implement GCP in workflow - https://sha.ws/automatic-upload-to-google-cloud-storage-with-github-actions.html
- [X] Dict keys in API output not ordered in correct way - reindex
- [X] Change "Date issued" to "Date Issued"
- [X] Accept list of iso codes or string seperated by comma for main python script - use regex to check correct format.
- [X] Several instances where "Online Browsing Platform" wrriten as "Online BrowsingPlatform" e.g BG, BY
- [ ] Validation in get_updates_df func, if input table is not type list & >1 then raise exception.
- [X] Update get_updates comments.
- [X] In code & comments change any var refereneces to "iso" to "iso3166" for clarification.
- [X] API can accept year input with greater or less than symbol.
- [ ] Main software can accept year input with greater or less than symbol.
- [X] Date missing from some elements of json in API.
- [X] Incorporate fix that takes into account multiple changes tables: e.g https://en.wikipedia.org/wiki/ISO_3166-2:PA
- [X] Some files saving as e.g "iso3166-updates-AD-[].csv" or "iso3166-updates-AD-.csv"
- [X] For secondary tables, add Edition/Newsletter as Online Browsing Platform - "The following changes to the entry are listed on ISO's online catalogue, the Online Browsing Platform:"
- [X] Add year range to iso3166_updates.py, allows user to input year range and relevant updates are returned.
- [X] Search by alpha3 code in API.
- [X] Instead of seperate alpha2 and alpha3 codes, if alpha2 empty then use alpha3 vice versa, only one set of alpha codes passed in.
- [X] Remove alpha3, would have to convert to alpha2.
- [X] Double check countries with no updates are empty like {} not {''} e.g BM, AX.
- [X] Remove any wiki references/links for regions within "Code/Subdivison Change" column, e.g AF
- [X] AM, GM, GH, ZM, AT, BN, BT, CG, CU, CY, DZ, EE, FM, IQ, IS, KI, KP, KZ, LT, NA, SI, SM, ST, SZ, TJ, TT missing 
Edition/Newsletter - should be OBP.
- [X] QA missing Edition/Newsletter - should be OBP.
- [ ] AF, BW, CZ - ensure that newlines in a column are not being concatted into one.
- [X] Add demo link to Colab to readme
- [X] Remove info about ISO3166-1 from intro on readme
- [ ] Go over year input parameter in software. 
- [X] https://us-central1-iso3166-updates.cloudfunctions.net/iso3166-updates?alpha2=FR&year=2018,201 - remove invalid years from year input and just use 2018 in this example.
- [ ] If invalid year/type input to python script, return all updates for inputted alpha2/s
- [ ] If invalid alpha2 input then export all updates data (python3 iso3166_updates.py --alpha2=adkad)
- [X] Unit tests that test if Edition/Newsletter columns are not empty.
- [X] Unit tests that test some alpha2 codes that have no Updates/Changes Section.
- [X] For all unit tests add country name beside alpha2 code & change e.g test_alpha1_code -> test_ad_code
- [X] Add how to use API using Python requests in ReadMe of api folder.
- [X] In API, for year param, if country has rows for selected year/year range, remove from output, rather than having [ ].
- [ ] Add space between colon and next char, e.g KE - "Deleted codes:KE-110, KE-200, KE-3" (has negative effect on some other update entries, destructive action)
- [X] For unit tests: output single row of expected dataframe to array (e.g sn_updates_df.iloc[1].to_numpy()).
- [ ] Add Code Coverage.
- [ ] Add green MIT logo to Readme (https://shields.io/category/license).
- [ ] Documentation on readthedocs.
- [ ] Create logo for API.
- [ ] If invalid input param put into URL then return empty dict instead.
- [X] Example on reamde and demo of how to use API using JS axios library (https://www.taniarascia.com/how-to-connect-to-an-api-with-javascript/).
- [X] Add diagram of CRON job workflow to worklfow dir on repo, including Email Cloud Func.
- [X] If json file is different in repo, upload to Cloud Storage.
- [X] Passing in single string as alpha2_codes to get_updates func returns None.
- [X] Remove if __name__ == "main" from software script. 
- [X] Software can accept list of alpha2 codes e.g "GY, HI, LU, MD"
- [X] Add try, except to Python requests.get in software, don't do it in unit tests.
- [ ] For 3rd test in test_get_updates_df tests, add array/list of correct column headers, use this array instead of list.
- [X] Finalise unit tests for get_updates() func.
- [X] Fix CSV file naming conventions when multiple alpha2 codes input to get_updates() func.
- [X] concat_csv param in get_updates() that determines whether to seperate inputted alpha2 updates into seperate or the same json file.
- [X] Create notification function that emails me when an update is found from CRON job workflow (https://documentation.matillion.com/docs/2434849). Add to workflows folder.
- [X] Upload any found updates from check_for_updates function to GCP bucket, download same object in email_updates func.
- [ ] Add month unit tests to api tests.
- [ ] Add month param to software.
- [X] Mention the earliest Date Issued was 2000-06-21.
- [ ] Add readthedocs badge - [![Documentation Status](https://readthedocs.org/projects/ansicolortags/badge/?version=latest)](http://ansicolortags.readthedocs.io/?badge=latest)
- [ ] Implemenet API gateway and endpoints for Cloud Func - update cloud arch image to include gateway, endpoints, load balancer, instance group, template etc.
- [ ] https://cloud.google.com/api-gateway/docs/passing-data
- [ ] Test concat_updates param in unit tests.
- [X] Add path-ignore keywords to GitHub Action.
- [X] Update api/readme to incorporate new api gateway.
- [X] Update api config / gateway if api config file changed. Documentation requires new one to be created. Create new one (iso3166-updates-config-2), delete old one (iso3166-updates), then create new one (iso3166-updates), delete old new one (iso3166-updates-config-2) 
- [ ] Add api gateway permission to SA.
- [ ] Add terraform script for cloud arch.
- [X] Mention intended audience in readme.
- [ ] Add api landing page with documentation, similar to restcountries.
- [X] Add years to input param of get_updates func, use tupele of (alpha2, year)
- [X] Reorder software metadata in setup.py to be in order of main func, create __description__ var.
- [X] Add download_url to setup.py - url of zipped package.
- [X] Update api tests to reflect updated url. 
- [ ] Mention schedule that check-for-updates is run and that it is appropriate to the general release of updates by the ISO3166.
- [ ] Remove all camel casing function names/vars, change to underscores and lowercase (https://peps.python.org/pep-0008/#function-and-variable-names).
- [X] Move from GCP to vercel.
- [X] Remove generate report from workflow
- [X] Create Python Flask App -> Deploy to Vercel -> Connect to domain.
- [X] Make bucket and iso3166-updates.json file publicly accessible.
- [X] When updating file in bucket, ensure it is publicy accessible.
- [X] Create vercel deployment pipeline in Github workflow.
- [ ] Create API endpoint for https://iso3166-updates.com/api and make main https://iso3166-updates.com a more visual frontend for the app with a dropdown of available countries, years etc.
- [X] Fix pytest badge on readme.
- [X] Unit test new api to double check invalid responses are returning correct message and status.
- [X] When check-for-updates is called and updates are found, programmatically raise an issue in the relevant repositories with a formatted description of the updates found (https://stackoverflow.com/questions/31767596/github-is-there-a-way-to-programmatically-file-an-issue). Instead of creating a new Issue each time, could update the same Issue with new data (https://gist.github.com/JeffPaine/3145490?permalink_comment_id=2558013).
- [X] Change default month in check-for-updates from 12 to 6.
- [X] Update api readmes to reflect new Create Issue functionality.
- [X] Reformat Date Issued from 2022-11-29 to 29-11-2022 (dd-mm-yyyy), mention that it's formatted as such as it's the most common format.
- [X] Have example on readme for getting all updates for all countries. 
- [X] After reformatting Date Issued, dates are out of order '27-11-2015' before 15-11-2016. May need to sort by column then convert into new format.
- [X] Append alpha-2 code to exported json filename. If more than one alpha-2 codes, seperate by comma.
- [X] iso.get_updates(["HI, LV"]) - passing in list of alpha-2 codes should pull updates.
- [X] Create unit test that check exported json filename contains multiple alpha2-codes appended to it.
- [X] Comment that concat_updates only works for JSON outputs as wouldn't for csv.
- [X] Actually return the json of updates from get_updates func. Update unit tests such that more of a focus on the output object than the json.
- [X] Append list of alpha-2 codes with updates to ISO3166-2 Updates: 09-05-2023 (here).
- [ ] https://github.com/codecov/codecov-action/issues/559
- [ ] Check for unit tests for passing in alpha3 code into API.
- [X] Reconfigure date format to format Y-m-d. Will need to rerun software.
- [X] Update check-for-updates API to use GCP Client library instead of requests after making storage bucket unpublic.
- [ ] In check-for-updates, verify that the new updates aren't already in updates.json object. Currently, it may just Create an Issue if updates are found in specified month period, regardless if they're in object. Current behaviour creates issue regardless.
- [X] Update api to reflect updates from frontend.
- [ ] API unit tests, pass in invalid 3 letter alpha-3 code, should return error message.
- [X] Remove request.args or request_json from api, probably only need one.
- [X] In check-for-updates, if new updates are found in month range, move old updates.json to an archive file with its date appened to filename, save new updates.json to root folder.
- [ ] In updates json, currently I think we're comparing the new updates found in specified month range with the whole of the updates JSON. Should iterate through new updates JSON to see if individual key string found in json.
- [X] Rename vars in check-for-updates to make more clear the current and old updates jsons.
- [X] Update return message in check-for-updates to be flask error message response.
- [X] Update software to be able to accept alpha-3 codes.
- [ ] Update API cloud arch to incorporate new archive folder and Create Issue functionality.
- [ ] Create Issue seems to add all updates from month range rather than just those updates that aren't in json.
- [ ] check-for-updates not working: need to publish new version of software, updates using d-m-Y format addtionally being appended with updates in format Y-m-d.
- [X] Unit tests to check all Date Issued in correct format. 
- [X] Change all date formats back to original in unit tests.
- [X] In API, incorporate different API endpoints for parameters, e.g /alpha2, /year, /months.
- [X] Update api.md to incorporate new endpoints/paths.
- [X] Unit tests for ">year" and < year , go through each entry and Date Issued, check they're all less than or greater than input year.
- [X] API unit tests for alpha2 + year path when no year specified (https://iso3166-updates-frontend-amckenna41.vercel.app/api/alpha2/AD/year) - should return all results for AD.
- [X] Double check '>' and '<' work for API url, may need to unicode decode these.
<!-- 
Create new config, update config file
gcloud api-gateway api-configs create NEW_CONFIG_ID --api=MY_API --openapi-spec=openapi2-functions.yaml 
Update gateway with config
gcloud api-gateway gateways update MY-GATEWAY --api=MY-API --api-config=NEW_CONFIG_ID --location=YOUR_LOCATION 
Update existing config
gcloud api-gateway api-configs update my-config --api=my-api --display-name="New Display Name"
Delete config
gcloud api-gateway api-configs delete CONFIG_ID --api=API_ID --project=PROJECT_ID
Need to enable Cloud Engine & Cloud Domains API to access LB services:
gcloud services enable ""
Connect LB to api gateway:
https://cloud.google.com/api-gateway/docs/gateway-serverless-neg
-->
